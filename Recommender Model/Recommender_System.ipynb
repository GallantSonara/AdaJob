{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**C23-PS046 - AdaJob Recommender System**"
      ],
      "metadata": {
        "id": "I_r5RvGOz8dp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This collab file is to train and export the recommender system model. The output of this file is a zipped recommender model file"
      ],
      "metadata": {
        "id": "22M09OjbzkCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparation"
      ],
      "metadata": {
        "id": "vwKyI3Wa0MPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install tfrs\n",
        "\n",
        "!pip install -q tensorflow-recommenders"
      ],
      "metadata": {
        "id": "LEfAqEJ20OhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZGYDaF-m5wZ"
      },
      "outputs": [],
      "source": [
        "#import the necessary modules\n",
        "\n",
        "import tensorflow as tf                   #a library for building ML models\n",
        "import tensorflow_recommenders as tfrs    #a library for building recommender system models\n",
        "import numpy as np                        #used to count num of unique user and airdrop jobs in the dataset\n",
        "import pandas as pd                       #to read csv file into pandas dataframe\n",
        "import shutil                             #to save the exported model files into a zip\n",
        "from typing import Dict, Text             #used in the loss computation of the combined model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaQhqcLGP0jL"
      },
      "outputs": [],
      "source": [
        "#read csv files to pandas\n",
        "\n",
        "df_airdrops = pd.read_csv('/content/Dataset Recommendation System - Task Dataset.csv', dtype={'task_id':'str'})\n",
        "df_enrollments = pd.read_csv('/content/Dataset Recommendation System - Enrollment Dataset_enroll only.csv',  dtype={'user_id': 'str', 'task_id':'str'})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check the dataframe\n",
        "\n",
        "df_enrollments.info()"
      ],
      "metadata": {
        "id": "H8azm-MsgQb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhbEvPJqxLec"
      },
      "outputs": [],
      "source": [
        "#convert the dataframe to a MapDataset\n",
        "\n",
        "enrollments = tf.data.Dataset.from_tensor_slices(dict(df_enrollments)).map(lambda x: {\n",
        "    \"task_title\": x[\"task_title\"],\n",
        "    \"user_id\": x[\"user_id\"],\n",
        "})\n",
        "\n",
        "airdrops = tf.data.Dataset.from_tensor_slices(dict(df_airdrops)).map(lambda x: x[\"task_title\"])\n",
        "\n",
        "print(type(enrollments))\n",
        "print(type(airdrops))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rS0eDfkjnjJL"
      },
      "outputs": [],
      "source": [
        "#shuffle the data\n",
        "#621 is the number of data available in the dataset\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "shuffled = enrollments.shuffle(621, seed=42, reshuffle_each_iteration=False)\n",
        "print(len(shuffled))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#divide the shuffled data into train and test set by a ratio of 80:20\n",
        "\n",
        "train = shuffled.take(497)\n",
        "test = shuffled.skip(497).take(124)"
      ],
      "metadata": {
        "id": "vSJBemeaVPG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train))\n",
        "print(len(test))"
      ],
      "metadata": {
        "id": "XxVu8c6pDtD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKROCiPo_5LJ"
      },
      "outputs": [],
      "source": [
        "#create arrays of unique airdrop titles and unique user ids to be used as vocabulary for the model's embedding later\n",
        "\n",
        "airdrop_titles = airdrops.batch(100)\n",
        "user_ids = enrollments.batch(1000).map(lambda x: x[\"user_id\"])\n",
        "\n",
        "unique_airdrop_titles = np.unique(np.concatenate(list(airdrop_titles)))\n",
        "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
        "\n",
        "print(unique_airdrop_titles[:10])\n",
        "#unique_user_ids[:10]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(unique_airdrop_titles))\n",
        "print(type(unique_user_ids))"
      ],
      "metadata": {
        "id": "Ejaq15_oWX2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(unique_airdrop_titles))\n",
        "print(len(unique_user_ids))"
      ],
      "metadata": {
        "id": "dwrOtn0lV45S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create the model"
      ],
      "metadata": {
        "id": "37RLQ0Yn0UPw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbIy1FP8aCTq"
      },
      "outputs": [],
      "source": [
        "#set the embedding dimension\n",
        "\n",
        "embedding_dimension = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHQZJEhXP93N"
      },
      "outputs": [],
      "source": [
        "#define the user model to embed the user ids as the query tower\n",
        "\n",
        "user_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.StringLookup(\n",
        "      vocabulary=unique_user_ids, mask_token=None),\n",
        "  # Additional +1 in embedding is for unknown tokens.\n",
        "  tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNUwfIJTQ332"
      },
      "outputs": [],
      "source": [
        "#define the airdrop model to embed the airdrop titles as the candidate tower\n",
        "\n",
        "airdrop_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.StringLookup(\n",
        "      vocabulary=unique_airdrop_titles, mask_token=None),\n",
        "  # Additional +1 in embedding is for unknown tokens.\n",
        "  tf.keras.layers.Embedding(len(unique_airdrop_titles) + 1, embedding_dimension)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dLDL6pZVPO8"
      },
      "outputs": [],
      "source": [
        "#define the metrics as FactorizedTopK (Top1, Top5, Top10, Top50, Top100)\n",
        "\n",
        "metrics = tfrs.metrics.FactorizedTopK(\n",
        "  candidates=airdrops.batch(128).map(airdrop_model)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJ61Iz2QTBw3"
      },
      "outputs": [],
      "source": [
        "#define task to get loss function\n",
        "\n",
        "task = tfrs.tasks.Retrieval(\n",
        "  metrics=metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8n7c5CHFp0ow"
      },
      "outputs": [],
      "source": [
        "#combine the query tower and candidate tower to build a full model\n",
        "\n",
        "class AirdropsModel(tfrs.Model):\n",
        "\n",
        "  def __init__(self, user_model, airdrop_model):\n",
        "    super().__init__()\n",
        "    self.airdrop_model: tf.keras.Model = airdrop_model\n",
        "    self.user_model: tf.keras.Model = user_model\n",
        "    self.task: tf.keras.layers.Layer = task\n",
        "\n",
        "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "    user_embeddings = self.user_model(features[\"user_id\"])\n",
        "    positive_airdrop_embeddings = self.airdrop_model(features[\"task_title\"])\n",
        "\n",
        "    return self.task(user_embeddings, positive_airdrop_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model"
      ],
      "metadata": {
        "id": "mbGahBlw0eVg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aW63YaqP2wCf"
      },
      "outputs": [],
      "source": [
        "#instantiate the model\n",
        "\n",
        "model = AirdropsModel(user_model, airdrop_model)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53QJwY1gUnfv"
      },
      "outputs": [],
      "source": [
        "#cache both train and test dataset\n",
        "\n",
        "cached_train = train.shuffle(621).batch(128).cache()\n",
        "cached_test = test.batch(64).cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxPntlT8EFOZ"
      },
      "outputs": [],
      "source": [
        "#train the model\n",
        "\n",
        "model.fit(cached_train, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-zu6HLODNeI"
      },
      "outputs": [],
      "source": [
        "#evaluate the model on the test dataset\n",
        "\n",
        "model.evaluate(cached_test, return_dict=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Recommendation Predictions"
      ],
      "metadata": {
        "id": "3A4N119p0x5D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRD6bEtZW_8j"
      },
      "outputs": [],
      "source": [
        "# Create a model that takes in user id and recommends airdrop jobs out of the entire airdrop jobs.\n",
        "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
        "index.index_from_dataset(\n",
        "  tf.data.Dataset.zip((airdrops.batch(100), airdrops.batch(100).map(model.airdrop_model)))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get recommendations.\n",
        "userid = 42\n",
        "_, titles = index(tf.constant([str(userid)]))\n",
        "recommended_titles = []\n",
        "\n",
        "for airdrop in titles:\n",
        "  print(airdrop)"
      ],
      "metadata": {
        "id": "Vx8WyaVi9h0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(titles))"
      ],
      "metadata": {
        "id": "3tBhdL6PIpUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titles = titles.numpy().tolist()\n",
        "print(type(titles))"
      ],
      "metadata": {
        "id": "V0soVbXoIt9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(titles)"
      ],
      "metadata": {
        "id": "Gtb_yI-mKmKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_target_user = df_enrollments[df_enrollments['user_id']==str(userid)]\n",
        "df_target_user"
      ],
      "metadata": {
        "id": "9UeS_aEjJhBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(titles[0][0])\n",
        "new0 = str(titles[0][0]).replace('b\\'', '')\n",
        "new0 = new0.replace('\\'', '')\n",
        "print(new0)\n"
      ],
      "metadata": {
        "id": "FrQy4C9TMwOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define a function to filter out recommended airdrop jobs that the user has already enrolled\n",
        "\n",
        "def delete_enrolled_tasks(userid, titles):\n",
        "  titles = titles.tolist()\n",
        "  recommended_titles = []\n",
        "  for i in range(len(titles[0])):\n",
        "    has_been_enrolled = False\n",
        "    cleaned_title = str(titles[0][i]).replace('b\\'', '')\n",
        "    cleaned_title = cleaned_title.replace('\\'', '')\n",
        "    for task_enrolled in df_enrollments[df_enrollments['user_id']==str(userid)].task_title:\n",
        "      if cleaned_title == task_enrolled:\n",
        "        has_been_enrolled = True\n",
        "        break\n",
        "    if not has_been_enrolled: \n",
        "      recommended_titles.append(cleaned_title)\n",
        "      print(cleaned_title)\n",
        "      #print('a')\n",
        "  return recommended_titles\n",
        "        \n",
        "\n",
        "#for task_finished in df_enrollments[df_enrollments['user_id']==str(userid)].task_id:\n",
        " # print(task_finished)"
      ],
      "metadata": {
        "id": "nlEKney9IoX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(titles[0]))"
      ],
      "metadata": {
        "id": "Gx-x8uks02Z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(titles[0][0])\n",
        "cleaned_title = str(titles[0][0]).replace('b\\'', '')\n",
        "cleaned_title = cleaned_title.replace('\\'', '')\n",
        "print(cleaned_title)"
      ],
      "metadata": {
        "id": "0PE2OEAy0i8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delete_enrolled_tasks(42,titles)"
      ],
      "metadata": {
        "id": "KcSC28pY0V-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(recommended_titles)"
      ],
      "metadata": {
        "id": "85h8vrOjOh3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Recommendations for user 42: {recommended_titles[:3]}\")"
      ],
      "metadata": {
        "id": "cQxNx8StKBga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export the Model with a SavedModel format"
      ],
      "metadata": {
        "id": "AtCYxS_81FdS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJkRNBfCW5_E"
      },
      "outputs": [],
      "source": [
        "# Export the model.\n",
        "\n",
        "tf.keras.models.save_model(index, 'content/test_model')\n",
        "shutil.make_archive('content/modelsavedwithkerasmeta', 'zip', 'content/test_model')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}